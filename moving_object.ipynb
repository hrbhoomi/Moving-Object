{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwxWlJE+n10kevQ11sX3Zl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"j-CXe2cYBZUg","executionInfo":{"status":"ok","timestamp":1712837027227,"user_tz":-330,"elapsed":428,"user":{"displayName":"Bhoomika Hr","userId":"04674468190722930153"}}},"outputs":[],"source":["# @title Import libraries\n","import numpy as np\n","import cv2\n","\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","np.random.seed(42)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"rh6H_N9lEqJp"}},{"cell_type":"code","source":["#Routine to fix\n","def fixColor(image):\n","    return(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"],"metadata":{"id":"y4Fg1jZ1BirZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Input\n","#Take a look at the input video\n","from IPython.display import Video\n","#Video(\"images/overpass.mp4\", embed=True)"],"metadata":{"id":"9OxwSOCmBlfi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Extract background in a video.\n","video_stream = cv2.VideoCapture('images/overpass.mp4')\n","\n","# Randomly select 30 frames\n","frameIds = video_stream.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=30)\n","\n","# Store selected frames in an array\n","frames = []\n","for fid in frameIds:\n","    video_stream.set(cv2.CAP_PROP_POS_FRAMES, fid)\n","    ret, frame = video_stream.read()\n","    frames.append(frame)\n","\n","video_stream.release()"],"metadata":{"id":"1d-51VqYBs3w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the median along the time axis\n","medianFrame = np.median(frames, axis=0).astype(dtype=np.uint8)\n","plt.imshow(fixColor(medianFrame))"],"metadata":{"id":"wDEZpqbuB1aA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the average along the time axis\n","avgFrame = np.average(frames, axis=0).astype(dtype=np.uint8)\n","plt.imshow(fixColor(avgFrame))"],"metadata":{"id":"-zAHV6IhB2rB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Processing a frame.\n","sample_frame=frames[0]\n","plt.imshow(fixColor(sample_frame))"],"metadata":{"id":"Il2V50q0B5_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grayMedianFrame = cv2.cvtColor(medianFrame, cv2.COLOR_BGR2GRAY)\n","plt.imshow(fixColor(grayMedianFrame))"],"metadata":{"id":"XXvhLjapB88p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graySample=cv2.cvtColor(sample_frame, cv2.COLOR_BGR2GRAY)\n","plt.imshow(fixColor(graySample))"],"metadata":{"id":"KeBi5pRtCACw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Remove background\n","# Remove background\n","dframe = cv2.absdiff(graySample, grayMedianFrame)\n","plt.imshow(fixColor(dframe))"],"metadata":{"id":"h00nPp0ACCn5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Blurring\n","blurred = cv2.GaussianBlur(dframe, (11,11), 0)\n","plt.imshow(fixColor(blurred))"],"metadata":{"id":"aGX1JZBRCFOc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Thresholding\n","ret, tframe= cv2.threshold(blurred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","plt.imshow(fixColor(tframe))"],"metadata":{"id":"9vK8KwDsCIBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Contour and Bounding Boxes\n","(cnts, _) = cv2.findContours(tframe.copy(), cv2.RETR_EXTERNAL,\n","                             cv2 .CHAIN_APPROX_SIMPLE)"],"metadata":{"id":"zLtjLQWtCKgn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for cnt in cnts:\n","    x,y,w,h = cv2.boundingRect(cnt)\n","    if y > 200:  #Disregard item that are the top of the picture\n","        cv2.rectangle(sample_frame,(x,y),(x+w,y+h),(0,255,0),2)\n","\n","plt.imshow(fixColor(sample_frame))"],"metadata":{"id":"Bnzv0NtMCNCx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Putting in together for processing video\n","writer = cv2.VideoWriter(\"output.mp4\",\n","                         cv2.VideoWriter_fourcc(*\"MP4V\"), 30,(640,480))"],"metadata":{"id":"ozQh-l8jCPT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create a new video stream and get total frame count\n","video_stream = cv2.VideoCapture('images/overpass.mp4')\n","total_frames=video_stream.get(cv2.CAP_PROP_FRAME_COUNT)\n","total_frames"],"metadata":{"id":"dc0jWzs7CSe0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["frameCnt=0\n","while(frameCnt < total_frames-1):\n","\n","    frameCnt+=1\n","    ret, frame = video_stream.read()\n","\n","    # Convert current frame to grayscale\n","    gframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    # Calculate absolute difference of current frame and\n","    # the median frame\n","    dframe = cv2.absdiff(gframe, grayMedianFrame)\n","    # Gaussian\n","    blurred = cv2.GaussianBlur(dframe, (11, 11), 0)\n","    #Thresholding to binarise\n","    ret, tframe= cv2.threshold(blurred,0,255,\n","                               cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","    #Identifying contours from the threshold\n","    (cnts, _) = cv2.findContours(tframe.copy(),\n","                                 cv2.RETR_EXTERNAL, cv2 .CHAIN_APPROX_SIMPLE)\n","    #For each contour draw the bounding bos\n","    for cnt in cnts:\n","        x,y,w,h = cv2.boundingRect(cnt)\n","        if y > 200: # Disregard items in the top of the picture\n","            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n","\n","    writer.write(cv2.resize(frame, (640,480)))\n","\n","#Release video object\n","video_stream.release()\n","writer.release()"],"metadata":{"id":"bva5oLN7CVEu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3ESKw1fWCYb2"},"execution_count":null,"outputs":[]}]}